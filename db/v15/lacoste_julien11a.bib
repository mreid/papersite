@InProceedings{lacoste_julien11a,
  title = {Approximate inference for the loss-calibrated Bayesian},
  author = {Simon Lacosteâ€“Julien and Ferenc Huszar and Zoubin Ghahramani},
  pages = {416--424},
  abstract = {We consider the problem of approximate inference in the context of Bayesian decision theory. Traditional approaches focus on approximating general properties of the posterior, ignoring the decision task -- and associated losses -- for which the posterior could be used. We argue that this can be suboptimal and propose instead to loss-calibrate the approximate inference methods with respect to the decision task at hand. We present a general framework rooted in Bayesian decision theory to analyze approximate inference from the perspective of losses, opening up several research directions. As a first loss-calibrated approximate inference attempt, we propose an EM-like algorithm on the Bayesian posterior risk and show how it can improve a standard approach to Gaussian process classification when losses are asymmetric.

[pdf][supplementary]},
  pdf = {/v15/lacoste_julien11a/lacoste_julien11a.pdf},
  supplementary = {Supplementary:/v15/lacoste_julien11a/lacoste_julien11aSupple.pdf},
}
