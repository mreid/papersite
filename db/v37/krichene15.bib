@InProceedings{krichene15,
  supplementary = {Supplementary:krichene15-supp.zip},
  title = {The Hedge Algorithm on a Continuum},
  author = {Walid Krichene and Maximilian Balandat and Claire Tomlin and Alexandre Bayen},
  pages = {805-813},
  abstract = {We consider an online optimization problem on a subset S of $R^n$ (not necessarily convex), in which a decision maker chooses, at each iteration t, a probability distribution $x^{(t)}$ over S, and seeks to minimize a cumulative expected loss, where each loss is a Lipschitz function revealed at the end of iteration t. Building on previous work, we propose a generalized Hedge algorithm and show a $O(\sqrt{t \log t})$ bound on the regret when the losses are uniformly Lipschitz and S is uniformly fat (a weaker condition than convexity). Finally, we propose a generalization to the dual averaging method on the set of Lebesgue-continuous distributions over S.},
}
