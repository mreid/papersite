@inproceedings{Komiyama13,
  pdf = {http://jmlr.org/proceedings/papers/v29/Komiyama13.pdf},
  title = {Multi-armed Bandit Problem with Lock-up Periods},
  author = {Komiyama, Junpei and Sato, Issei and Nakagawa, Hiroshi},
  pages = {116-132},
  abstract = {We investigate a stochastic multi-armed bandit problem in which the forecaster's choice is restricted. In this problem, rounds are divided into lock-up periods and the forecaster must select the same arm throughout a period. While there has been much work on finding optimal algorithms for the stochastic multi-armed bandit problem,  their use under restricted conditions is not obvious. We extend the application ranges of these algorithms by proposing their natural conversion from ones for the stochastic bandit problem (index-based algorithms and greedy algorithms) to ones for the multi-armed bandit problem with lock-up periods. We prove that the regret of the converted algorithms is $O(\log{T} + L_{max} )$, where $T$ is the total number of rounds and $L_{max}$ is the maximum size of the lock-up periods. The regret is preferable, except for the case when the maximum size of the lock-up periods is large. For these cases, we propose a meta-algorithm that results in a smaller regret by using a empirical best arm for large periods. We empirically compare and discuss these algorithms.},
}
