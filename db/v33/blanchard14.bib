@InProceedings{blanchard14,
  supplementary = {Supplementary:blanchard14-supp.pdf},
  section = {notable},
  title = {{Decontamination of Mutually Contaminated Models}},
  author = {Blanchard, Gilles and Scott, Clayton},
  pages = {1-9},
  abstract = {A variety of machine learning problems are characterized by   data sets that are drawn from multiple different convex   combinations of a fixed set of base distributions.  We call this a mutual contamination model.  In such problems, it is often of interest to   recover these base distributions, or otherwise discern   their properties. This work focuses on the problem of   classification with multiclass label noise, in a general   setting where the noise proportions are unknown and the   true class distributions are nonseparable and potentially   quite complex. We develop a procedure for decontamination   of the contaminated models from data, which then   facilitates the design of a consistent discrimination rule. Our   approach relies on a novel method for estimating the error   when projecting one distribution onto a convex combination   of others, where the projection is with respect to an   information divergence known as the separation distance.   Under sufficient conditions on the amount of noise and   purity of the base distributions, this projection procedure   successfully recovers the underlying class distributions. Connections to   novelty detection, topic modeling, and other learning problems are also   discussed.},
}
