@InProceedings{honorio14,
  supplementary = {Supplementary:honorio14-supp.pdf},
  title = {{Tight Bounds for the Expected Risk of Linear Classifiers and PAC-Bayes Finite-Sample Guarantees}},
  author = {Honorio, Jean and Jaakkola, Tommi},
  pages = {384-392},
  abstract = {"We analyze the expected risk of linear classifiers for a fixed weight vector in the ""minimax"" setting. That is, we analyze the worst-case risk among all data distributions with a given mean and covariance. We provide a simpler proof of the tight polynomial-tail bound for general random variables. For sub-Gaussian random variables, we derive a novel tight exponential-tail bound. We also provide new PAC-Bayes finite-sample guarantees when training data is available. Our ""minimax"" generalization bounds are dimensionality-independent and O(sqrt(1/m)) for m samples."},
}
