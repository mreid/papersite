@InProceedings{malek14,
  supplementary = {Supplementary:malek14-supp.pdf},
  title = {Linear Programming for Large-Scale Markov Decision Problems},
  author = {Alan Malek and Yasin Abbasi-Yadkori and Peter Bartlett},
  pages = {496-504},
  abstract = {We consider the problem of controlling a Markov decision  process (MDP) with a large state space, so as to minimize average cost.  Since it is intractable to compete with the optimal policy for large  scale problems, we pursue the more modest goal of competing with a  low-dimensional family of policies. We use the dual linear programming  formulation of the MDP average cost problem, in which the variable is  a stationary distribution over state-action pairs, and we consider a  neighborhood of a low-dimensional subset of the set of stationary  distributions (defined in terms of state-action features) as  the comparison class.  We propose two techniques, one based on stochastic convex optimization,  and one based on constraint sampling. In both cases, we give bounds  that show that the performance of our algorithms approaches the best  achievable by any policy in the comparison class. Most importantly,  these results depend on the size of the comparison class, but not  on the size of the state space.  Preliminary experiments  show the effectiveness of the proposed algorithms in a queuing  application.},
  section = {cycle-2},
}
