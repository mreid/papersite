@InProceedings{li11a,
  title = {A New Algorithm for Compressed Counting with Applications in Shannon Entropy Estimation in Dynamic Data},
  author = {Ping Li and Cun-Hui Zhang},
  pages = {477--496},
  abstract = {Efficient estimation of the moments and Shannon entropy of data streams is an important task in modern machine learning and data mining.  To estimate the Shannon entropy, it suffices to accurately estimate the $\alpha$-th  moment with $\Delta = |1-\alpha|\approx0$. To guarantee that the error of estimated Shannon entropy is within a $\nu$-additive factor, the method of {\em symmetric stable random projections} requires $O\left(\frac{1}{\nu^2\Delta^2}\right)$ samples, which is extremely expensive. The first paper~\citep{Proc:Li_SODA09} in {\em Compressed Counting (CC)}, based on {\em skewed-stable random projections}, supplies a substantial improvement by reducing the sample complexity to $O\left(\frac{1}{\nu^2\Delta}\right)$, which is still  expensive. The followup work~\citep{Proc:Li_UAI09} provides a  practical algorithm, which is however  difficult to analyze theoretically.In this paper, we propose a new   accurate algorithm for Compressed Counting, whose sample complexity is only $O\left(\frac{1}{\nu^2}\right)$ for $\nu$-additive Shannon entropy estimation. The constant factor for this bound is merely about 6.  In addition, we prove that our algorithm achieves an upper bound of the Fisher information and in fact it is  close to $100\%$  statistically optimal.  An empirical study is  conducted to verify the accuracy of our algorithm.},
  pdf = {/v19/li11a/li11a.pdf},
}
