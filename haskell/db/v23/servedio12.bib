@InProceedings{servedio12,
  title = {Attribute-Efficient Learning andWeight-Degree Tradeoffs for Polynomial Threshold Functions},
  author = {Rocco   Servedio and Li-Yang Tan and Justin Thaler},
  pages = {14.1--14.19},
  abstract = {We study the challenging problem of learning decision lists attribute-efficiently, giving both positive and negative results. Our main positive result is a new tradeoff between the running time and mistake bound for learning length-\emph{k} decision lists over \emph{n} Boolean variables. When the allowed running time is relatively high, our new mistake bound improves significantly on the mistake bound of the best previous algorithm of Klivans and Servedio (Klivans and Servedio, 2006). Our main negative result is a new lower bound on the \emph{weight} of any degree-\emph{d} polynomial threshold function (PTF) that computes a particular decision list over \emph{k} variables (the ``ODD-MAX-BIT'' function). The main result of Beigel (Beigel, 1994) is a weight lower bound of 2^{Ω(\emph{k}/\emph{d}^{2})}, which was shown to be essentially optimal for \emph{d} ≤ \emph{k}^{1/3} by Klivans and Servedio. Here we prove a 2^{Ω(√\emph{k/d})}  lower bound, which improves on Beigel's lower bound for \emph{d} > \emph{k}^{1/3}. This lower bound establishes strong limitations on the effectiveness of the Klivans and Servedio approach and suggests that it may be difficult to improve on our positive result. The main tool used in our lower bound is a new variant of Markov's classical inequality which may be of independent interest; it provides a bound on the derivative of a univariate polynomial in terms of both its degree \emph{and} the size of its coefficients.},
  pdf = {http://jmlr.org/proceedings/papers/v23/servedio12/servedio12.pdf},
}
