@InProceedings{lin09a,
  title = {Learning Sparse Markov Network Structure via Ensemble-of-Trees Models},
  author = {Yuanqing Lin and Shenghuo Zhu and Daniel Lee and Ben Taskar},
  pages = {360--367},
  abstract = {Learning the sparse structure of a general  Markov network is a hard problem. One of the  main difficulties is the computation of its generally  intractable partition function. To circumvent  this difficulty, this paper proposes to learn  the network structure using an ensemble-of-trees  (ET) model. The ET model was first introduced  by Meila and Jaakkola [1], and it approximates  a Markov network using a mixture of all possible  (super-exponentially many) spanning trees.  The advantage of the ET model is that, although  it needs to sum over super-exponentially many  trees, its partition function as well as data likelihood  can be computed in a closed form. Furthermore,  since the ET model tends to represent  a Markov network using as small number  of trees as possible, it provides a natural regularization  for finding a sparse network structure.  Our simulation results show that the proposed  ET approach is able to accurately recover  the true Markov network connectivity and significantly  outperform the state-of-art approaches  for both discrete and continuous random variable  networks. Furthermore, we also demonstrate the  usage of the ET model for discovering the network  of words from blog posts.},
  pdf = {http://jmlr.org/proceedings/papers/v5/lin09a/lin09a.pdf},
}
