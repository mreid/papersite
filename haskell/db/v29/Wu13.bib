@inproceedings{Wu13,
  pdf = {http://jmlr.org/proceedings/papers/v29/Wu13.pdf},
  title = {Multi-Label Classification with Unlabeled Data: An Inductive Approach},
  author = {Wu, Le and Zhang, Min-Ling},
  pages = {197-212},
  abstract = {The problem of multi-label classification has attracted great interests in the last decade. Multi-label classification refers to the problems where an example that is represented by a \emph{single} instance can be assigned to \emph{more than one} category. Until now, most of the researches on multi-label classification have focused on supervised settings whose assumption is that large amount of labeled training data is available. Unfortunately, labeling training example is expensive and time-consuming, especially when it has more than one label. However, in many cases abundant unlabeled data is easy to obtain. Current attempts toward exploiting unlabeled data for multi-label classification work under the \emph{transductive} setting, which aim at making predictions on existing unlabeled data while can not generalize to new unseen data. In this paper, the problem of \emph{inductive} semi-supervised multi-label classification is studied, where a new approach named \textsl{iMLCU}, i.e. \emph{inductive Multi-Label Classification with Unlabeled data}, is proposed. We formulate the inductive semi-supervised multi-label learning as an optimization problem of learning linear models and ConCave Convex Procedure \textsl{(CCCP)} is applied to optimize the non-convex optimization problem. Empirical studies on twelve diversified real-word multi-label learning tasks clearly validate the superiority of \textsl{iMLCU} against the other well-established multi-label learning approaches.},
}
