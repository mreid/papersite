@INPROCEEDINGS{zhu14,
  author = {Zhu, Yue and Wu, Jianxin and Jiang, Yuan and Zhou, Zhi-Hua},
  title = {Learning with Augmented Multi-Instance View},
  pages = {234-249},
  abstract = {In this paper, we propose the Augmented Multi-Instance View (AMIV)
	framework to construct a better model by exploiting augmented information.
	For example, abstract screening tasks may be difficult because only
	abstract information is available, whereas the performance can be
	improved when the abstracts of references listed in the document
	can be exploited as augmented information. If each abstract is represented
	as an instance (i.e., a feature vector) x, then with the augmented
	information, it can be represented as an instance-bag pair (x;B),
	where B is a bag of instances (i.e., the abstracts of references).
	Note that if x has a label y, then we assume that there must exist
	at least one instance in the bag B having the label y. We regard
	x and B as two views, i.e., a single-instance view augmented with
	a multi-instance view, and propose the AMIV-lss approach by establishing
	a latent semantic subspace between the two views. The AMIV framework
	can be applied when the augmented information is presented as multi-instance
	bags and to the best of our knowledge, such a learning with augmented
	multi-instance view problem has not been touched before. Experimental
	results on twelve TechPaper datasets, five PubMed data sets and a
	WebPage data set validate the effectiveness of our AMIV-lss approach.},
}
